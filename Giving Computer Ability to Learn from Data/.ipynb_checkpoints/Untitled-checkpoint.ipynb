{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Machine learning is a subfield of Artificial Intelligence. Machine learning algorithms are self learning algorithms which do not require programmers to program them for specific need. They draw conclusions from the data on their own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Types of Machine Learning\n",
    "\n",
    "1. Supervised Learning\n",
    "2. Unsupervised Learning\n",
    "3. Reinforcement Learning\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "Main goal of supervised learning is to predict the output(label) given the set of input. Supervised here means that while we are training the model we have set of samples where the desired output(labels) is known. Further two types are\n",
    "\n",
    "1. Classification\n",
    "2. Regression\n",
    "\n",
    "### Classification\n",
    "\n",
    "Supervised learning with discrete class labels such as e-mail spam detection is a Classification problem. Here the sample set are marked with spam or not spam and the model is trained to predict these discrete lables.\n",
    "Email spam detection is example of binary classification. Class label does not have to be binary they can be multi-class as well. Hand Written Digit Recognition is multi class label exmaple where input image is a feature and model has to predict the digit (0-9) from it.\n",
    "Below graph represent concept of binary classification. Given 30 Samples 15 are of Positive Class and 15 are of Negative class. In this case the dataset is two dimensional and have two associated features x1 and x2. The dotted line represents the decision boundary which seperates two classes\n",
    "\n",
    "\n",
    "<img src=\"first.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "### Regression\n",
    "\n",
    "Supervised learning where the class label is a continous value rather than a fixed value. Predicting stock prices is a typical example of Regression Task. \n",
    "In regression we are given with predictor(features) varibale and a continous value(outcome) and we try to find a relationship between them that allows to predict continous value\n",
    "For example to prdict math SAT score we have data of number of hours spent in studying and marks obtained of some students we can use this data to predict the scores of other students by inputing the hours spent in studying. We can use linear regression. Using the sample set we try to find a line which fits the data (square distance of each data point from line is minized) and then this line intercept and slope is used to predict the continous values given the features as input.\n",
    "\n",
    "<img src=\"second.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "In reinforcement learning target is to train an agent which learn by interacting with the environment. With each action it recieves a environment state and a reward which indicates how well it perfomed. Since there is concept of reward signal it is somewhat include feedback (similar to supervised learning) but this reward me be correct or not. Therefore, the objective is to increase the cumluative reward by trial and error method. Here is the workflow.\n",
    "\n",
    "<img src=\"third.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "In supervised learning the right answer was known beforehand training. (We have labels to classify right or wrong preictions is made by the model). In unsupervised learning data structure is unknown. These algorithms allows us to find the hidden data structures \n",
    "\n",
    "### Clustering\n",
    "\n",
    "Clustering is an unsupervised learning algorithm which find the number of groups in the data(clusters). Below images show the result of clustering algorithm, which discovered three different groups in the data\n",
    "\n",
    "<img src=\"fourth.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "### Dimentionality Reduction (Data Compression)\n",
    "\n",
    "Another subfield of Unsupervised learning. Dimentionality Reduction is common approach used to remove noise from the data(unwanted features) which can degrade the performance of the algorithm and also compresses the data to lower subspace which is easy to visualize while retaining most the relavent information. \n",
    "Sometimes, dimentionality redudction is helpful to reduce the dimensions of the data so that it can be seen on one,two or three dimensional graphs. Below example shows how a 3D data can be lowered to 2D to see the pattern in data. \n",
    "\n",
    "<img src=\"fifth.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic terminology\n",
    "\n",
    "Below is the data set of Iris flower which have three different species : Setosa, Versicolor, Viriginica. Each row represents a single data sample.\n",
    "<img src=\"sixth.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "This dataset has 4 features which can be written in matrix form where each row represent one sample of the data so the dimensions of the matrix is 150 x 4 \n",
    "\n",
    "\n",
    "$\\left[ \\begin{array}{cccc}\n",
    "x1 & x2 & x3 & x4 \\\\\n",
    "x1 & x2 & x3 & x4 \\\\\n",
    "\\ldots & \\ldots & \\ldots & \\ldots \\\\\n",
    "x1 & x2 & x3 & x4 \\\\ \\end{array} \\right]$\n",
    "\n",
    "Any sample can be accessed as a vector \n",
    "\n",
    "$\\left[ \\begin{array}{cccc}\n",
    "x1 & x2 & x3 & x4 \\\\ \\end{array} \\right]$\n",
    "\n",
    "Similarly, the vector of class labels is stored as a 150 dimensional vector where y belongs to three species of the Iris Flower ** y belongs to {Setosa, Veriscolor, Viriginica}**\n",
    "\n",
    "$\\left[ \\begin {array} {cccc}\n",
    "y1 \\\\\n",
    "y2\\\\\n",
    "y3\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "y150 \\\\ \\end{array} \\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoadMap for building Machine Learning Systems\n",
    "\n",
    "Typical workflow of machine learning models in predictive modeling\n",
    "\n",
    "<img src=\"eight.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "## Preprocessing \n",
    "\n",
    "Raw data is not always comes in the shape that is necessary for the optimal performance of the algorithm. Preprocessing is one of the ** most crucial ** step needed to be performed before training an algorithm. For example in Iris Dataset if we have series of images of flowers as raw data then we need to extract the useful features like color, hue, intensity etc.\n",
    "* Some time we need to transform the features to [0,1] range or a standard normal distribution with zero mean and unit varinace.\n",
    "* Some of the features sometimes are highly coorelated so they are redundant. So dimentionality reduction in that case can be used to compress or lower the data. This results in low storage space required to store the data and algorithms run faster.\n",
    "\n",
    "\n",
    "## Training and selecting predictive models\n",
    "\n",
    "Different algorithms are developed to solve different tasks. So it is better to check performance of many algorithm before selecting a particular algorithm for prediction. Performance of algorithm are generally defined by the accuracy metric which is the amount of correctly classified instances\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
